#!/usr/bin/env bash
# File overview:
# - Purpose: One-command local spin-up for backend (DB+Redis via Docker) and Expo client with API pointing to localhost.
# - Steps: Free ports, docker compose up, build server, ensure DB schema via ts-node, start server, smoke-test APIs, start Expo.
# - Inputs: PORT (server), EXPO_PORT (Expo dev server). Exports EXPO_PUBLIC_API_BASE_URL and flags.
set -euo pipefail

THIS_DIR="$(cd "$(dirname "$0")" && pwd)"
CLIENT_DIR="$(cd "$THIS_DIR/.." && pwd)"
SERVER_DIR="$(cd "$CLIENT_DIR/../KC-MVP-server" && pwd)"
SERVER_PORT=${PORT:-3001}
EXPO_PORT=${EXPO_PORT:-8081}

# ============================================================================
# Helper Functions
# ============================================================================

log_info() {
  echo "â„¹ï¸  $1"
}

log_success() {
  echo "âœ… $1"
}

log_error() {
  echo "âŒ $1" >&2
}

log_warning() {
  echo "âš ï¸  $1"
}

# Check if port is available
is_port_available() {
  local port="$1"
  ! lsof -ti tcp:"$port" >/dev/null 2>&1
}

# Helper to free port
kill_port() {
  local port="$1"
  local pids
  pids=$(lsof -ti tcp:"$port" || true)
  if [[ -n "$pids" ]]; then
    log_info "Freeing port $port (PIDs: $pids)"
    kill -9 $pids >/dev/null 2>&1 || true
  fi
}

# Test endpoint with retry logic
test_endpoint_with_retry() {
  local url="$1"
  local max_attempts="${2:-3}"
  local attempt=1
  
  while [[ $attempt -le $max_attempts ]]; do
    if curl -sf "$url" >/dev/null 2>&1; then
      return 0
    fi
    if [[ $attempt -lt $max_attempts ]]; then
      sleep 1
    fi
    attempt=$((attempt + 1))
  done
  return 1
}

# ============================================================================
# Cleanup Function
# ============================================================================

cleanup() {
  echo ""
  log_info "Cleaning up..."
  
  # Stop server
  if [[ -n "${SERVER_PID:-}" ]]; then
    log_info "Stopping server (PID: $SERVER_PID)..."
    kill "$SERVER_PID" >/dev/null 2>&1 || true
    wait "$SERVER_PID" 2>/dev/null || true
  fi
  
  # Optionally stop Docker (if SKIP_DOCKER_CLEANUP is not set)
  if [[ -z "${SKIP_DOCKER_CLEANUP:-}" ]]; then
    log_info "Stopping Docker containers..."
    (cd "$SERVER_DIR" && docker compose down >/dev/null 2>&1 || true)
  fi
  
  log_success "Cleanup complete"
}
trap cleanup EXIT INT TERM

# ============================================================================
# Pre-flight Checks
# ============================================================================

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸš€ Starting Local E2E Environment Setup"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Check Node.js version
log_info "Checking Node.js version..."
REQUIRED_NODE_VERSION="18.0.0"
CURRENT_NODE_VERSION=$(node -v | sed 's/v//')
if ! node -e "const required = '$REQUIRED_NODE_VERSION'.split('.').map(Number); const current = '$CURRENT_NODE_VERSION'.split('.').map(Number); if (current[0] < required[0] || (current[0] === required[0] && current[1] < required[1])) process.exit(1);" 2>/dev/null; then
  log_error "Node.js version $CURRENT_NODE_VERSION is too old. Required: >= $REQUIRED_NODE_VERSION"
  exit 1
fi
log_success "Node.js version: $CURRENT_NODE_VERSION"

# Check required files
log_info "Checking required files..."
if [[ ! -f "$SERVER_DIR/package.json" ]]; then
  log_error "package.json not found in $SERVER_DIR"
  exit 1
fi

if [[ ! -f "$CLIENT_DIR/package.json" ]]; then
  log_error "package.json not found in $CLIENT_DIR"
  exit 1
fi
log_success "Required files found"

# Check Docker availability
log_info "Checking Docker availability..."
if ! command -v docker >/dev/null 2>&1; then
  log_error "Docker not found. Please install Docker Desktop."
  exit 1
fi

# Check if Docker daemon is running
if ! docker info >/dev/null 2>&1; then
  log_error "Docker daemon is not running. Please start Docker Desktop."
  exit 1
fi
log_success "Docker is available and running"

# ============================================================================
# Port Management
# ============================================================================

log_info "Checking and freeing ports..."

# Check and free server port
if ! is_port_available "$SERVER_PORT"; then
  log_warning "Port $SERVER_PORT is in use. Attempting to free it..."
  kill_port "$SERVER_PORT"
  sleep 2
  if ! is_port_available "$SERVER_PORT"; then
    log_error "Port $SERVER_PORT is still in use. Please free it manually."
    exit 1
  fi
fi

# Check and free Expo port
if ! is_port_available "$EXPO_PORT"; then
  log_warning "Port $EXPO_PORT is in use. Attempting to free it..."
  kill_port "$EXPO_PORT"
  sleep 2
  if ! is_port_available "$EXPO_PORT"; then
    log_error "Port $EXPO_PORT is still in use. Please free it manually."
    exit 1
  fi
fi

# Free other common ports that might interfere
kill_port 8080
kill_port 8080
kill_port 3000
kill_port 5432 # Free Postgres port to ensure we connect to Docker, not local DB

log_success "Ports are ready"

# ============================================================================
# Docker Services Setup
# ============================================================================

log_info "Starting Docker services (Postgres & Redis)..."

# MODIFIED: Preserve data between runs - only stop containers, don't delete volumes
log_info "Stopping existing Docker containers (preserving data)..."
(cd "$SERVER_DIR" && docker compose down >/dev/null 2>&1 || true)
# NOTE: Volume deletion commented out to preserve data between runs
# Uncomment the following lines if you need a fresh database:
# (cd "$SERVER_DIR" && docker compose down -v >/dev/null 2>&1 || true)
# docker volume rm kc-mvp-server_pgdata 2>/dev/null || true

if docker compose version >/dev/null 2>&1; then
  (cd "$SERVER_DIR" && docker compose up -d || {
    log_error "Failed to start Docker Compose services"
    exit 1
  })
elif command -v docker-compose >/dev/null 2>&1; then
  (cd "$SERVER_DIR" && docker-compose up -d || {
    log_error "Failed to start Docker Compose services"
    exit 1
  })
else
  log_error "docker compose not found"
  exit 1
fi

# Wait for Postgres to be ready
log_info "Waiting for Postgres to be ready..."
POSTGRES_READY=0
for i in {1..30}; do
  POSTGRES_CONTAINER=$(docker ps -q -f name=postgres)
  if [[ -n "$POSTGRES_CONTAINER" ]] && docker exec "$POSTGRES_CONTAINER" pg_isready -U kc >/dev/null 2>&1; then
    POSTGRES_READY=1
    break
  fi
  if [[ $i -eq 30 ]]; then
    log_error "Postgres did not become ready in time"
    exit 1
  fi
  sleep 1
done
if [[ $POSTGRES_READY -eq 1 ]]; then
  log_success "Postgres is ready"
fi

# Wait for Redis to be ready
log_info "Waiting for Redis to be ready..."
REDIS_READY=0
for i in {1..30}; do
  REDIS_CONTAINER=$(docker ps -q -f name=redis)
  if [[ -n "$REDIS_CONTAINER" ]] && docker exec "$REDIS_CONTAINER" redis-cli ping >/dev/null 2>&1; then
    REDIS_READY=1
    break
  fi
  if [[ $i -eq 30 ]]; then
    log_error "Redis did not become ready in time"
    exit 1
  fi
  sleep 1
done
if [[ $REDIS_READY -eq 1 ]]; then
  log_success "Redis is ready"
fi

# ============================================================================
# Database Migration: UUID Conversion (run early, before init-db)
# ============================================================================

log_info "Running UUID conversion migration (if tables exist)..."
MIGRATION_FILE="$SERVER_DIR/src/database/migration-uuid-conversion.sql"
if [[ ! -f "$MIGRATION_FILE" ]]; then
  log_warning "Migration file not found: $MIGRATION_FILE - skipping migration"
else
  POSTGRES_CONTAINER=$(docker ps -q -f name=postgres)
  if [[ -n "$POSTGRES_CONTAINER" ]]; then
    # Check if tables exist before running migration
    TABLES_EXIST=$(docker exec "$POSTGRES_CONTAINER" psql -U kc -d kc_db -tAc \
      "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='public' AND table_name IN ('chat_messages', 'message_read_receipts', 'chat_conversations');" 2>/dev/null || echo "0")
    
    if [[ "$TABLES_EXIST" -gt "0" ]]; then
      # Run migration with error handling - ignore errors if columns are already UUID
      if docker exec -i "$POSTGRES_CONTAINER" psql -U kc -d kc_db < "$MIGRATION_FILE" 2>/dev/null; then
        log_success "UUID conversion migration completed"
      else
        # Check if error is because columns are already UUID (which is fine)
        SENDER_ID_TYPE=$(docker exec "$POSTGRES_CONTAINER" psql -U kc -d kc_db -tAc \
          "SELECT data_type FROM information_schema.columns WHERE table_name='chat_messages' AND column_name='sender_id';" 2>/dev/null || echo "")
        if [[ "$SENDER_ID_TYPE" == "uuid" ]]; then
          log_success "UUID conversion migration skipped (columns already UUID)"
        else
          log_warning "UUID conversion migration had errors (will retry after init-db)"
        fi
      fi
    else
      log_info "Tables don't exist yet - migration will run after init-db"
    fi
  else
    log_warning "Postgres container not found - skipping UUID migration"
  fi
fi

# ============================================================================
# Server Build
# ============================================================================

cd "$SERVER_DIR"
log_info "Building server..."

# Clean old build artifacts
log_info "Cleaning old build artifacts..."
rm -rf "$SERVER_DIR/dist" "$SERVER_DIR/build.err.log" 2>/dev/null || true

# Ensure dependencies are installed
if [[ ! -d node_modules ]]; then 
  log_info "Installing server dependencies (node_modules missing)..."
  npm ci || npm install
elif [[ ! -f node_modules/body-parser/package.json ]]; then
  log_info "Installing server dependencies (body-parser missing)..."
  npm install
fi

# Verify critical dependencies are installed
if [[ ! -f node_modules/body-parser/package.json ]]; then
  log_warning "Critical dependency 'body-parser' not found. Installing..."
  npm install body-parser
  if [[ ! -f node_modules/body-parser/package.json ]]; then
    log_error "Failed to install body-parser. Aborting."
    exit 1
  fi
fi

# Build with error logging
log_info "Running npm run build..."
if ! npm run build 2>build.err.log; then
  log_error "Build failed. Errors:"
  if [[ -f build.err.log ]]; then
    tail -100 build.err.log
  fi
  log_error "TSC fallback attempt..."
  if ! ./node_modules/.bin/tsc -p tsconfig.build.json 2>>build.err.log; then
    log_error "TSC fallback also failed. Aborting."
    exit 1
  fi
fi

# Verify build output
if [[ ! -f "$SERVER_DIR/dist/main.js" ]]; then
  log_error "Build output missing: dist/main.js"
  log_warning "Running tsc fallback..."
  if ! ./node_modules/.bin/tsc -p tsconfig.build.json; then
    log_error "TSC fallback failed. Aborting."
    exit 1
  fi
  if [[ ! -f "$SERVER_DIR/dist/main.js" ]]; then
    log_error "Build output still missing after fallback. Aborting."
    exit 1
  fi
fi

log_success "Server build completed"

# Check for required build files
REQUIRED_JS=(
  "$SERVER_DIR/dist/main.js"
  "$SERVER_DIR/dist/app.module.js"
  "$SERVER_DIR/dist/controllers/health.controller.js"
  "$SERVER_DIR/dist/controllers/chat.controller.js"
  "$SERVER_DIR/dist/items/items.controller.js"
  "$SERVER_DIR/dist/items/items.module.js"
)

MISSING_ANY=0
for f in "${REQUIRED_JS[@]}"; do
  if [[ ! -f "$f" ]]; then MISSING_ANY=1; fi
done

if [[ $MISSING_ANY -eq 1 ]]; then
  log_warning "Build output incomplete â€” switching to ts-node runtime."
  FALLBACK_SERVER_JS=1
fi

# ============================================================================
# Environment Configuration
# ============================================================================

log_info "Configuring environment variables..."

# Database configuration
export REDIS_URL=${REDIS_URL:-redis://localhost:6379}
export POSTGRES_HOST=${POSTGRES_HOST:-127.0.0.1}
export POSTGRES_PORT=${POSTGRES_PORT:-5435}
export POSTGRES_USER=${POSTGRES_USER:-kc}
export POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-kc_password}
export POSTGRES_DB=${POSTGRES_DB:-kc_db}
export PORT="$SERVER_PORT"
export DATABASE_URL=${DATABASE_URL:-postgresql://$POSTGRES_USER:$POSTGRES_PASSWORD@$POSTGRES_HOST:$POSTGRES_PORT/$POSTGRES_DB}

# Environment configuration (CRITICAL)
export ENVIRONMENT=${ENVIRONMENT:-development}
export NODE_ENV=${NODE_ENV:-development}

# CORS configuration (IMPORTANT)
export CORS_ORIGIN=${CORS_ORIGIN:-"http://localhost:8081,http://localhost:3000,http://localhost:19006"}

# JWT Secret (CRITICAL - required by server)
if [[ -z "${JWT_SECRET:-}" ]]; then
  log_info "Generating JWT_SECRET for local development..."
  export JWT_SECRET=$(node -e "console.log(require('crypto').randomBytes(32).toString('hex'))")
  log_success "JWT_SECRET generated: ${JWT_SECRET:0:20}..."
else
  if [[ ${#JWT_SECRET} -lt 32 ]]; then
    log_error "JWT_SECRET must be at least 32 characters long (current: ${#JWT_SECRET})"
    log_error "Generate a new one: node -e \"console.log(require('crypto').randomBytes(32).toString('hex'))\""
    exit 1
  fi
  log_success "Using provided JWT_SECRET: ${JWT_SECRET:0:20}..."
fi

# Google OAuth Configuration (CRITICAL for auth to work)
export GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID:-430191522654-o70t2qnqc4bvpvmbpak7unog7pvp9c95.apps.googleusercontent.com}
export EXPO_PUBLIC_GOOGLE_WEB_CLIENT_ID=${EXPO_PUBLIC_GOOGLE_WEB_CLIENT_ID:-430191522654-o70t2qnqc4bvpvmbpak7unog7pvp9c95.apps.googleusercontent.com}
export EXPO_PUBLIC_GOOGLE_IOS_CLIENT_ID=${EXPO_PUBLIC_GOOGLE_IOS_CLIENT_ID:-430191522654-q05j71a8lu3e1vgf75c2r2jscgckb4mm.apps.googleusercontent.com}
export EXPO_PUBLIC_GOOGLE_ANDROID_CLIENT_ID=${EXPO_PUBLIC_GOOGLE_ANDROID_CLIENT_ID:-430191522654-jno2tkl1dotil0mkf4h4hahfk4e4gas8.apps.googleusercontent.com}

echo ""
log_info "Environment Configuration:"
echo "   Environment: $ENVIRONMENT"
echo "   Node Env: $NODE_ENV"
echo "   CORS Origin: $CORS_ORIGIN"
echo "   GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID:0:20}..."
echo "   Web Client ID: ${EXPO_PUBLIC_GOOGLE_WEB_CLIENT_ID:0:20}..."

# ============================================================================
# Database Initialization
# ============================================================================

log_info "Ensuring DB tables (init script)..."

if ! SKIP_FULL_SCHEMA=1 NODE_OPTIONS= \
  POSTGRES_HOST="$POSTGRES_HOST" \
  POSTGRES_PORT="$POSTGRES_PORT" \
  POSTGRES_USER="$POSTGRES_USER" \
  POSTGRES_PASSWORD="$POSTGRES_PASSWORD" \
  POSTGRES_DB="$POSTGRES_DB" \
  DATABASE_URL="$DATABASE_URL" \
  npx ts-node -r tsconfig-paths/register src/scripts/init-db.ts; then
  log_error "DB init failed. Aborting."
  exit 1
fi
log_success "Database initialized"

# ============================================================================
# Database Migration: UUID Conversion (retry after init-db if needed)
# ============================================================================

log_info "Ensuring UUID conversion migration is applied..."
MIGRATION_FILE="$SERVER_DIR/src/database/migration-uuid-conversion.sql"
if [[ ! -f "$MIGRATION_FILE" ]]; then
  log_warning "Migration file not found: $MIGRATION_FILE - skipping migration"
else
  POSTGRES_CONTAINER=$(docker ps -q -f name=postgres)
  if [[ -n "$POSTGRES_CONTAINER" ]]; then
    # Check if columns are already UUID
    SENDER_ID_TYPE=$(docker exec "$POSTGRES_CONTAINER" psql -U kc -d kc_db -tAc \
      "SELECT data_type FROM information_schema.columns WHERE table_name='chat_messages' AND column_name='sender_id';" 2>/dev/null || echo "")
    
    if [[ "$SENDER_ID_TYPE" != "uuid" ]] && [[ -n "$SENDER_ID_TYPE" ]]; then
      # Run migration
      if docker exec -i "$POSTGRES_CONTAINER" psql -U kc -d kc_db < "$MIGRATION_FILE" 2>/dev/null; then
        log_success "UUID conversion migration completed"
      else
        log_warning "UUID conversion migration had errors (columns may already be UUID or tables may not exist)"
      fi
    else
      log_success "UUID conversion already applied (columns are UUID)"
    fi
  else
    log_warning "Postgres container not found - skipping UUID migration"
  fi
fi

# ============================================================================
# Database Migration: Ensure Required Columns (google_id, roles)
# ============================================================================

log_info "Ensuring required columns exist in user_profiles..."
COLUMN_MIGRATION_FILE="$SERVER_DIR/src/database/migration-ensure-columns.sql"
if [[ ! -f "$COLUMN_MIGRATION_FILE" ]]; then
  log_warning "Column migration file not found: $COLUMN_MIGRATION_FILE - skipping"
else
  POSTGRES_CONTAINER=$(docker ps -q -f name=postgres)
  if [[ -n "$POSTGRES_CONTAINER" ]]; then
    # Run migration (it's safe to run multiple times - it checks if columns exist)
    if docker exec -i "$POSTGRES_CONTAINER" psql -U kc -d kc_db < "$COLUMN_MIGRATION_FILE" 2>/dev/null; then
      log_success "Required columns migration completed"
    else
      log_warning "Column migration had errors (columns may already exist)"
    fi
  else
    log_warning "Postgres container not found - skipping column migration"
  fi
fi

# ============================================================================
# Database Migration: Add Missing Columns (parent_manager_id, settings, etc.)
# ============================================================================

log_info "Running missing columns migration..."
MISSING_COLUMNS_MIGRATION_FILE="$SERVER_DIR/src/database/migration-add-missing-columns.sql"
if [[ ! -f "$MISSING_COLUMNS_MIGRATION_FILE" ]]; then
  log_warning "Missing columns migration file not found: $MISSING_COLUMNS_MIGRATION_FILE - skipping"
else
  POSTGRES_CONTAINER=$(docker ps -q -f name=postgres)
  if [[ -n "$POSTGRES_CONTAINER" ]]; then
    # Run migration (it's safe to run multiple times - it checks if columns exist)
    if docker exec -i "$POSTGRES_CONTAINER" psql -U kc -d kc_db < "$MISSING_COLUMNS_MIGRATION_FILE" 2>/dev/null; then
      log_success "Missing columns migration completed"
    else
      log_warning "Missing columns migration had warnings (columns may already exist)"
    fi
  else
    log_warning "Postgres container not found - skipping missing columns migration"
  fi
fi

# ============================================================================
# Database Migration: Fix Schema Synchronization (avatar_url, tasks table)
# ============================================================================

log_info "Running schema synchronization migration..."
SCHEMA_SYNC_MIGRATION_FILE="$SERVER_DIR/src/database/migration-fix-schema-sync.sql"
if [[ ! -f "$SCHEMA_SYNC_MIGRATION_FILE" ]]; then
  log_warning "Schema sync migration file not found: $SCHEMA_SYNC_MIGRATION_FILE - skipping"
else
  POSTGRES_CONTAINER=$(docker ps -q -f name=postgres)
  if [[ -n "$POSTGRES_CONTAINER" ]]; then
    # Run migration (it's safe to run multiple times - it checks if columns/tables exist)
    if docker exec -i "$POSTGRES_CONTAINER" psql -U kc -d kc_db < "$SCHEMA_SYNC_MIGRATION_FILE" 2>/dev/null; then
      log_success "Schema synchronization migration completed"
    else
      log_warning "Schema sync migration had warnings (schema may already be correct)"
    fi
  else
    log_warning "Postgres container not found - skipping schema sync migration"
  fi
fi

# ============================================================================
# Database Migration: Posts Table (ensure posts table exists with correct schema)
# ============================================================================

log_info "Ensuring posts table exists with correct schema..."
POSTGRES_CONTAINER=$(docker ps -q -f name=postgres)
if [[ -n "$POSTGRES_CONTAINER" ]]; then
  # Check if posts table exists and has correct structure
  POSTS_TABLE_EXISTS=$(docker exec "$POSTGRES_CONTAINER" psql -U kc -d kc_db -tAc \
    "SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name='posts');" 2>/dev/null || echo "false")
  
  POSTS_HAS_AUTHOR_ID=$(docker exec "$POSTGRES_CONTAINER" psql -U kc -d kc_db -tAc \
    "SELECT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name='posts' AND column_name='author_id');" 2>/dev/null || echo "false")
  
  if [[ "$POSTS_TABLE_EXISTS" == "t" ]] && [[ "$POSTS_HAS_AUTHOR_ID" == "t" ]]; then
    log_success "Posts table already exists with correct schema - no migration needed"
  else
    # Table doesn't exist or has wrong structure - create/update it safely
    log_info "Creating or updating posts table..."
    
    # Check if table exists but has wrong structure (legacy table with user_id/item_id/data)
    POSTS_HAS_LEGACY_STRUCTURE=$(docker exec "$POSTGRES_CONTAINER" psql -U kc -d kc_db -tAc \
      "SELECT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name='posts' AND column_name='user_id');" 2>/dev/null || echo "false")
    
    if [[ "$POSTS_HAS_LEGACY_STRUCTURE" == "t" ]]; then
      log_warning "Detected legacy posts table structure - migrating to new schema..."
      # Backup data if exists (though legacy table likely has different structure)
      POSTS_COUNT=$(docker exec "$POSTGRES_CONTAINER" psql -U kc -d kc_db -tAc \
        "SELECT COUNT(*) FROM posts;" 2>/dev/null || echo "0")
      if [[ "$POSTS_COUNT" -gt "0" ]]; then
        log_warning "Posts table has $POSTS_COUNT rows - these will be lost due to schema change"
        log_warning "If you need to preserve this data, please export it manually before running this script"
      fi
    fi
    
    # Create posts table with correct schema (safe to run multiple times)
    docker exec -i "$POSTGRES_CONTAINER" psql -U kc -d kc_db <<EOF 2>/dev/null || true
-- Create posts table if it doesn't exist, or recreate if it has wrong structure
DO \$\$
BEGIN
    -- Drop table only if it has wrong structure (legacy)
    IF EXISTS (
        SELECT 1 FROM information_schema.columns 
        WHERE table_name='posts' AND column_name='user_id'
    ) THEN
        DROP TABLE IF EXISTS posts CASCADE;
    END IF;
    
    -- Create table if it doesn't exist
    IF NOT EXISTS (
        SELECT 1 FROM information_schema.tables WHERE table_name='posts'
    ) THEN
        CREATE TABLE posts (
            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
            author_id UUID NOT NULL REFERENCES user_profiles(id) ON DELETE CASCADE,
            task_id UUID REFERENCES tasks(id) ON DELETE SET NULL,
            title VARCHAR(255) NOT NULL,
            description TEXT,
            images TEXT[],
            likes INTEGER DEFAULT 0,
            comments INTEGER DEFAULT 0,
            post_type VARCHAR(50) DEFAULT 'task_completion',
            metadata JSONB DEFAULT '{}'::jsonb,
            created_at TIMESTAMPTZ DEFAULT NOW(),
            updated_at TIMESTAMPTZ DEFAULT NOW()
        );
        
        CREATE INDEX IF NOT EXISTS idx_posts_author_id ON posts(author_id);
        CREATE INDEX IF NOT EXISTS idx_posts_task_id ON posts(task_id);
        CREATE INDEX IF NOT EXISTS idx_posts_created_at ON posts(created_at DESC);
        CREATE INDEX IF NOT EXISTS idx_posts_post_type ON posts(post_type);
        
        DROP TRIGGER IF EXISTS update_posts_updated_at ON posts;
        CREATE TRIGGER update_posts_updated_at 
            BEFORE UPDATE ON posts 
            FOR EACH ROW 
            EXECUTE FUNCTION update_updated_at_column();
    END IF;
END \$\$;
EOF
    
    if [[ $? -eq 0 ]]; then
      log_success "Posts table ensured with correct schema"
    else
      log_warning "Posts table creation had warnings (table may already exist)"
    fi
  fi
else
  log_warning "Postgres container not found - skipping posts table creation"
fi

# Final check: ensure dependencies are installed before starting server
cd "$SERVER_DIR"
if [[ ! -f node_modules/body-parser/package.json ]]; then
  log_warning "body-parser not found. Installing dependencies..."
  npm install
  if [[ ! -f node_modules/body-parser/package.json ]]; then
    log_error "Failed to install dependencies. Aborting."
    exit 1
  fi
fi

# ============================================================================
# Server Startup
# ============================================================================

log_info "Starting server on http://localhost:$SERVER_PORT ..."
if [[ -n "${FALLBACK_SERVER_JS:-}" ]]; then
  log_warning "Using fallback: running TS directly via ts-node"
  # ensure dev deps
  if [[ ! -d node_modules ]]; then npm ci || npm install; fi
  SKIP_FULL_SCHEMA=1 \
  GOOGLE_CLIENT_ID="$GOOGLE_CLIENT_ID" \
  EXPO_PUBLIC_GOOGLE_WEB_CLIENT_ID="$EXPO_PUBLIC_GOOGLE_WEB_CLIENT_ID" \
  DATABASE_URL="$DATABASE_URL" \
  REDIS_URL="$REDIS_URL" \
  NODE_ENV="$NODE_ENV" \
  ENVIRONMENT="$ENVIRONMENT" \
  CORS_ORIGIN="$CORS_ORIGIN" \
  JWT_SECRET="$JWT_SECRET" \
  PORT="$PORT" \
  node -r ts-node/register -r tsconfig-paths/register src/main.ts &
else
  SKIP_FULL_SCHEMA=1 \
  GOOGLE_CLIENT_ID="$GOOGLE_CLIENT_ID" \
  EXPO_PUBLIC_GOOGLE_WEB_CLIENT_ID="$EXPO_PUBLIC_GOOGLE_WEB_CLIENT_ID" \
  DATABASE_URL="$DATABASE_URL" \
  REDIS_URL="$REDIS_URL" \
  NODE_ENV="$NODE_ENV" \
  ENVIRONMENT="$ENVIRONMENT" \
  CORS_ORIGIN="$CORS_ORIGIN" \
  JWT_SECRET="$JWT_SECRET" \
  PORT="$PORT" \
  node dist/main.js &
fi
SERVER_PID=$!

# Wait for server to be healthy
log_info "Waiting for server to be healthy..."
ATTEMPTS=0
MAX_ATTEMPTS=80
until curl -sf http://localhost:"$SERVER_PORT"/health >/dev/null 2>&1 || curl -sf http://localhost:"$SERVER_PORT"/ >/dev/null 2>&1; do
  ATTEMPTS=$((ATTEMPTS+1))
  if [[ $ATTEMPTS -gt $MAX_ATTEMPTS ]]; then
    log_error "Server did not become healthy in time"
    exit 1
  fi
  if [[ $((ATTEMPTS % 10)) -eq 0 ]]; then
    log_info "Still waiting... ($ATTEMPTS/$MAX_ATTEMPTS)"
  fi
  sleep 0.25
done
log_success "Server is up and healthy"

# ============================================================================
# API Tests
# ============================================================================

log_info "Running API Health Tests..."
if ! ./scripts/test-api-health.sh "$SERVER_PORT"; then
  log_error "API Health Tests failed. Aborting."
  exit 1
fi
log_success "API Health Tests passed"

# ============================================================================
# Client (Expo) Startup
# ============================================================================

cd "$CLIENT_DIR"
log_info "Starting Expo (API=http://localhost:$SERVER_PORT)"

# CRITICAL: Remove old static HTML file that interferes with Expo web
if [[ -f "$CLIENT_DIR/public/index.html" ]]; then
  log_warning "Removing old static HTML file (public/index.html) that interferes with Expo web"
  mv "$CLIENT_DIR/public/index.html" "$CLIENT_DIR/public/index.html.old" 2>/dev/null || true
fi

if [[ ! -d node_modules ]]; then 
  log_info "Installing client dependencies..."
  npm ci || npm install
fi

export EXPO_PUBLIC_API_BASE_URL=http://localhost:"$SERVER_PORT"
export EXPO_PUBLIC_USE_BACKEND=1
export EXPO_PUBLIC_USE_FIRESTORE=0

# Clear cache before starting to avoid circular dependency issues
log_info "Clearing Metro cache..."
rm -rf "$CLIENT_DIR/.expo" "$CLIENT_DIR/node_modules/.cache" 2>/dev/null || true

# ============================================================================
# Final User Message
# ============================================================================

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ‰ Local E2E Environment is Ready!"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ğŸ“ Server: http://localhost:$SERVER_PORT"
echo "ğŸ“ Expo:   http://localhost:$EXPO_PORT"
echo ""
echo "ğŸ”§ Environment: $ENVIRONMENT"
echo "ğŸ—„ï¸  Database: $POSTGRES_HOST:$POSTGRES_PORT/$POSTGRES_DB"
echo "ğŸ“¦ Redis: $REDIS_URL"
echo ""
echo "ğŸ’¡ Tips:"
echo "   - Press Ctrl+C to stop all services"
echo "   - Server logs: Check terminal output"
echo "   - Database: docker exec -it \$(docker ps -q -f name=postgres) psql -U kc -d kc_db"
echo "   - Redis: docker exec -it \$(docker ps -q -f name=redis) redis-cli"
echo ""
echo "âš ï¸  IMPORTANT: Open http://localhost:$EXPO_PORT in your browser"
echo "   (NOT http://localhost:3001 or any other port)"
echo ""
echo "   If you see the 'coming soon' page:"
echo "   1. Clear browser cache (Ctrl+Shift+R or Cmd+Shift+R)"
echo "   2. Make sure you're opening http://localhost:$EXPO_PORT"
echo "   3. Check browser console for errors (F12)"
echo "   4. Try incognito/private mode"
echo ""
echo "   The app should show either:"
echo "   - LandingSiteScreen (if web mode = 'site')"
echo "   - LoginScreen or HomeScreen (if web mode = 'app')"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Start Expo
EXPO_DEV_SERVER_PORT="$EXPO_PORT" npx expo start --port "$EXPO_PORT" --web --clear
